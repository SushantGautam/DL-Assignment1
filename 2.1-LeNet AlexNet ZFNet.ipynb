{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33b06747-7872-4f11-8271-0a6974934fdc",
   "metadata": {},
   "source": [
    "## LeNet Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f639925-bc9c-49e0-9e56-01705a39a7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             156\n",
      "            Conv2d-2           [-1, 16, 10, 10]           2,416\n",
      "            Linear-3                  [-1, 120]          48,120\n",
      "            Linear-4                   [-1, 84]          10,164\n",
      "            Linear-5                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.05\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.29\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "lenet = LeNet().to(\"cpu\")\n",
    "print(lenet)\n",
    "summary(lenet, (1,32,32), device = \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4138b33-c06d-48f7-a0f8-d277b597747c",
   "metadata": {},
   "source": [
    "### Manually calculation is done to match this result for LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb29639-54c6-4aff-aefb-edfcb42cd3c5",
   "metadata": {},
   "source": [
    "## AlexNet as per your slide 13, ch2.\n",
    "### However I couldnt get 61M params as mentioned on this one.  I tried"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91197f5d-560e-4fb3-94ff-6a04fd8ba678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (conv1): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=6400, out_features=4096, bias=True)\n",
      "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (fc3): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 54, 54]          11,712\n",
      "         MaxPool2d-2           [-1, 96, 26, 26]               0\n",
      "            Conv2d-3          [-1, 256, 26, 26]         614,656\n",
      "         MaxPool2d-4          [-1, 256, 12, 12]               0\n",
      "            Conv2d-5          [-1, 384, 12, 12]         885,120\n",
      "            Conv2d-6          [-1, 384, 12, 12]       1,327,488\n",
      "            Conv2d-7          [-1, 256, 12, 12]         884,992\n",
      "         MaxPool2d-8            [-1, 256, 5, 5]               0\n",
      "            Linear-9                 [-1, 4096]      26,218,496\n",
      "           Linear-10                 [-1, 4096]      16,781,312\n",
      "           Linear-11                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 50,820,776\n",
      "Trainable params: 50,820,776\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 5.48\n",
      "Params size (MB): 193.87\n",
      "Estimated Total Size (MB): 199.53\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 96, 11, stride=4)\n",
    "        self.pool1 =  nn.MaxPool2d(3, stride=2)\n",
    "        self.conv2 = nn.Conv2d(96, 256, 5, padding=2)\n",
    "        self.pool2 =  nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(256, 384, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(384, 384, 3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(384, 256, 3, padding=1)\n",
    "        self.pool3 =  nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(256 * 5 * 5, 4096)  ##########\n",
    "        self.fc2 = nn.Linear(4096, 4096, )\n",
    "        self.fc3 = nn.Linear(4096, 1000, )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)), )\n",
    "        x = self.pool2(self.conv2(x))\n",
    "        x =  self.conv3(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool3(F.relu(self.conv5(x)))\n",
    "        x = x.view(-1, 256 * 5 * 5) ##########\n",
    "        # x =  torch.flatten(x)\n",
    "        x = F.relu(F.dropout(self.fc1(x)), 0.5)\n",
    "        x = F.relu(F.dropout(self.fc2(x)), 0.5)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "alexnet = AlexNet().to(\"cpu\")\n",
    "print(alexnet)\n",
    "summary(alexnet, (1,224,224), device = \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cfc12d-03fa-4447-a876-9a5e12dbb394",
   "metadata": {},
   "source": [
    "### Manually calculation is done to match this result for Alexnet. \n",
    "\n",
    "I also modified above to accomodate AlexNet at https://pytorch.org/vision/main/_modules/torchvision/models/alexnet.html\n",
    "This contains: extra AdaptiveAvgPool2d\n",
    "\n",
    "And got 61M Params !! Yay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8e02965-6940-4492-b3ab-ed945b1728c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (fc1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (fc3): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 55, 55]          23,296\n",
      "         MaxPool2d-2           [-1, 64, 27, 27]               0\n",
      "            Conv2d-3          [-1, 192, 27, 27]         307,392\n",
      "         MaxPool2d-4          [-1, 192, 13, 13]               0\n",
      "            Conv2d-5          [-1, 384, 13, 13]         663,936\n",
      "            Conv2d-6          [-1, 256, 13, 13]         884,992\n",
      "            Conv2d-7          [-1, 256, 13, 13]         590,080\n",
      "         MaxPool2d-8            [-1, 256, 6, 6]               0\n",
      " AdaptiveAvgPool2d-9            [-1, 256, 6, 6]               0\n",
      "           Linear-10                 [-1, 4096]      37,752,832\n",
      "           Linear-11                 [-1, 4096]      16,781,312\n",
      "           Linear-12                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 61,100,840\n",
      "Trainable params: 61,100,840\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 4.51\n",
      "Params size (MB): 233.08\n",
      "Estimated Total Size (MB): 238.17\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 11, stride=4, padding=2)\n",
    "        self.pool1 =  nn.MaxPool2d(3, stride=2)\n",
    "        self.conv2 = nn.Conv2d(64, 192, 5, padding=2)\n",
    "        self.pool2 =  nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(192, 384, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(384, 256, 3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.pool3 =  nn.MaxPool2d(3, stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))  ## this was not on your net on slide\n",
    "\n",
    "        self.fc1 = nn.Linear(256 * 6 * 6, 4096)  ##########\n",
    "        self.fc2 = nn.Linear(4096, 4096, )\n",
    "        self.fc3 = nn.Linear(4096, 1000, )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)), )\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool3(F.relu(self.conv5(x)))\n",
    "        x= self.avgpool(x)\n",
    "        x = x.view(-1, 256 * 6 * 6) ##########\n",
    "        # x =  torch.flatten(x)\n",
    "        x = F.relu(F.dropout(self.fc1(x)), 0.5)\n",
    "        x = F.relu(F.dropout(self.fc2(x)), 0.5)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "alexnet = AlexNet().to(\"cpu\")\n",
    "print(alexnet)\n",
    "summary(alexnet, (3,224,224), device = \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d29d9dd-c946-468b-9ced-6b400fc95f30",
   "metadata": {},
   "source": [
    "## Now Lets see ZFNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21cbfaf4-a64d-41b6-8bb7-28e9595311dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZFNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))\n",
      "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(192, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (fc1): Linear(in_features=18432, out_features=4096, bias=True)\n",
      "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (fc3): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 111, 111]           9,472\n",
      "         MaxPool2d-2           [-1, 64, 55, 55]               0\n",
      "            Conv2d-3          [-1, 192, 55, 55]         307,392\n",
      "         MaxPool2d-4          [-1, 192, 27, 27]               0\n",
      "            Conv2d-5          [-1, 512, 27, 27]         885,248\n",
      "            Conv2d-6         [-1, 1024, 27, 27]       4,719,616\n",
      "            Conv2d-7          [-1, 512, 27, 27]       4,719,104\n",
      "         MaxPool2d-8          [-1, 512, 13, 13]               0\n",
      " AdaptiveAvgPool2d-9            [-1, 512, 6, 6]               0\n",
      "           Linear-10                 [-1, 4096]      75,501,568\n",
      "           Linear-11                 [-1, 4096]      16,781,312\n",
      "           Linear-12                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 107,020,712\n",
      "Trainable params: 107,020,712\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 25.25\n",
      "Params size (MB): 408.25\n",
      "Estimated Total Size (MB): 434.08\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ZFNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ZFNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 7, stride=2, padding=2) #change CONV1 filter from 11,4 to 7,2\n",
    "        self.pool1 =  nn.MaxPool2d(3, stride=2)   #same as ALexnet\n",
    "        self.conv2 = nn.Conv2d(64, 192, 5, padding=2)\n",
    "        self.pool2 =  nn.MaxPool2d(3, stride=2)  #same as ALexnet\n",
    "\n",
    "        self.conv3 = nn.Conv2d(192, 512, 3, padding=1) #CONV3: 512 filters instead of 384\n",
    "        self.conv4 = nn.Conv2d(512, 1024, 3, padding=1) #CONV4: 1024 filters \n",
    "        self.conv5 = nn.Conv2d(1024, 512, 3, padding=1) #CONV5: 512 filters\n",
    "        self.pool3 =  nn.MaxPool2d(3, stride=2)   #same as ALexnet\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))  ## this was not on your net on slide\n",
    "\n",
    "        self.fc1 = nn.Linear(512 * 6 * 6, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096, )\n",
    "        self.fc3 = nn.Linear(4096, 1000, )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)), )\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool3(F.relu(self.conv5(x)))\n",
    "        x= self.avgpool(x)\n",
    "        x = x.view(-1, 512 * 6 * 6) ##########\n",
    "        # x =  torch.flatten(x)\n",
    "        x = F.relu(F.dropout(self.fc1(x)), 0.5)\n",
    "        x = F.relu(F.dropout(self.fc2(x)), 0.5)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "zFNet = ZFNet().to(\"cpu\")\n",
    "print(zFNet)\n",
    "summary(zFNet, (3,224,224), device = \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1839f3c-6166-4f15-b8fe-c6f3d27b6169",
   "metadata": {},
   "source": [
    "### Compare the number of parameters.  \n",
    "AlexNet: 61,100,840 ---   ZFNet: 107,020,712 params;  \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
